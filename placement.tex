\chapter{Placing applications in large SpiNNaker machines}
	
	In the previous chapter I tackled the problem of scale in generating routes
	for very large networks such as SpiNNaker. In this work the centroid traffic
	pattern was used as an approximation of the expected network traffic
	generated by `well behaved' neural network simulation software running on
	SpiNNaker. The traffic produced largely exhibits strong locality, that is
	most communication occurs between either nearby nodes or clusters of nodes.
	In reality, neural simulation applications are not specified geometrically
	but rather as abstract graphs of communicating neurons
	\cite{davison08,eliasmith13}. Applications must then \emph{place} these
	neurons onto nodes in a SpiNNaker system, attempting maximise communication
	locality.
	
	In this chapter I re-evaluate the suitability of simulated annealing as a
	technique for finding high quality placements for large parallel
	applications. Though this technique had fallen out of fashion in the field of
	application placement by the early 1990s, it has found wide use for placing
	components in computer chip and FPGA designs. In the intervening years,
	placement problems in super computers have grown in size from tens or
	hundreds of nodes to millions, a scale at which chip placement techniques
	were operating in the mid 1990s. I adapt the simulated annealing algorithm
	used by the VPR academic circuit placement software to produce placements for
	applications running on SpiNNaker. In that in a range of real and synthetic
	benchmarks simulated annealing produces high quality placements enabling
	efficient use of SpiNNaker's network resources.
	
	
	%In the field of chip design, Moore's `Law' \cite{moore65,moore75} observes a
	%similar exponential growth in the number of components within a single chip.
	%Today modern processors contain billions of components and an analagous
	%placement problem exists in attempting to place interconnected components
	%near to eachother. In this chapter I explore the techniques used for circuit
	%placement and adapt one such technique, Simulated Annealing (SA)
	%\cite{kirkpatrick83}, for use in application placement. Despite some early
	%interest in SA for application placement in the 1980s and early 1990s, the
	%technique has since fallen out of favour. I find that at the scales of modern
	%placement problems SA-based placement is able to produce solutions of
	%superiour quality to contemporary methods.
	%
	%TODO: SUMMARISE RESULTS...
	
	\section{Related work}
		
		The placement problem has been tackled independently in the literature by
		researchers in both the application and chip placement communities. In this
		survey I cover application and chip placement separately as these two
		communities have remained largely isolated from one another. First I
		explore the techniques applied to application placement before moving on to
		contrast this with the techniques used in circuit placement.
		
		In the application placement literature, the placement problem is often
		referred under the umbrella term `mapping'. Unfortunately term is often
		used more broadly to include other tasks such as routing and application
		partitioning. To avoid ambiguity I use the term `placement', as preferred
		by the chip and FPGA design communities, to refer specifically to the
		problem of assigning nodes in an application's communication graph to nodes
		in a machine's connectivity graph.
		
		\subsection{Application placement algorithms}
			
			TODO: GENERAL INTRO
			
			\subsubsection{Application-specific approaches (manual placement)}
				
				In the case of some applications such as finite element modelling
				\cite{bermejo13}, the structure of the problem itself leads to a
				natural placement of the computation on nodes in a machine. For example
				when simulating a 3D volume in an node super computer with a $3 \times
				4 \times 2$ 3D torus or mesh topology network, the modelled volume
				might be divided into as in figure \ref{fig:fem-partitioning}. Each
				cuboid in the model is then assigned to the corresponding node in the
				network topology.
				
				\begin{figure}
					\center
					\buildfig{figures/fem-partitioning.tex}
					
					\caption{Example partitioning of a 3D space to fit into a super
					computer with a $3\times4\times2$ torus or mesh topology.}
					\label{fig:fem-partitioning}
				\end{figure}
				
				When the number of dimensions in a problem do not match that of the
				underlying network architecture, the common solution is to either
				divide only along a subset of the axes or to divide into additional
				pieces on the existing axes \cite{gilge14}.
			
			\subsubsection{Sequential placement}
				
				In the case where a placement solution is non-obvious one of the
				simplest and most popular strategies is to apply a simple sequential
				placement algorithm. Sequential placement algorithms function by
				iterating over the vertices in the application's communication graph
				and assigning them to a free node in the target machine. Sequential
				placement algorithms are differentiated by the order in which they
				iterate over vertices in the communication graph and fill nodes in the
				target machine. A number of widely used orderings are described below.
				
				\begin{figure}
					\center
					\begin{subfigure}{0.32\linewidth}
						\center
						\buildfig{figures/sequential-row-order.tex}
						\caption{Row-order}
						\label{fig:sequential-row-order}
					\end{subfigure}
					\begin{subfigure}{0.32\linewidth}
						\center
						\buildfig{figures/sequential-alternating.tex}
						\caption{Alternating}
						\label{fig:sequential-alternating}
					\end{subfigure}
					\begin{subfigure}{0.32\linewidth}
						\center
						\buildfig{figures/sequential-hilbert.tex}
						\caption{Hilbert curve}
						\label{fig:sequential-hilbert}
					\end{subfigure}
					
					\caption{Space-filling curves in 2D mesh and torus topologies.}
					\label{fig:sequential}
				\end{figure}
				
				Super computer management software such as SLURM \cite{yoo03} and Blue
				Gene's system software \cite{gilge14} by default na\"ively iterate over
				vertices in an application communication graph in the order they are
				provided. The nodes in the target machine are then iterated over in a
				simple space-filling curve through the network topology. Figure
				\ref{fig:hilbert-placement} illustrates the default patterns available
				in these software packages. The row-order (figure
				\ref{fig:sequential-row-order}) and alternating (figure
				\ref{fig:sequential-alternating}) curves correspond with 2D versions of
				the default node assignment orders used in SLURM and BlueGene systems.
				
				\begin{figure}
					\center
					\buildfig{figures/hilbert-placement.tex}
					
					\caption{A Hilbert curve, coloured from blue to red.}
					\label{fig:hilbert-placement}
				\end{figure}
				
				The Cray extensions to SLURM software provide a Hilbert curve
				\cite{hilbert91} (figure \ref{fig:sequential-hilbert}) node assignment
				order. Unlike the row-order and alternating space filling curves the
				Hilbert curve ensures that pairs of vertices close together in the node
				iteration order are also close together in the target machine's network
				\cite{moon01, zumbusch99}. Figure \ref{fig:hilbert-placement} shows a
				5$^\textrm{th}$-order Hilbert curve where each point in the curve is
				coloured according to its position along the curve. In this figure it
				is possible to see that nearby positions in the curve (which share
				similar colours) are also close in 2D space.
				
				When the proximity of vertices in the vertex-ordering supplied by an
				application is a good estimator of those vertices communication
				requirements, the sequential assignment schemes discussed above can be
				very effective. These techniques have also proven adequate in
				small-scale and densely connected applications such as early neural
				simulations running on prototype SpiNNaker machines with tens of nodes
				\cite{galluppi10} but growing beyond this scale has proven problematic.
				
				\begin{figure}
					\center
					\begin{subfigure}{0.45\linewidth}
						\center
						\buildfig{figures/rcm-initial.tex}
						
						\caption{Original permutation}
						\label{fig:rcm-initial}
					\end{subfigure}
					\begin{subfigure}{0.45\linewidth}
						\center
						\buildfig{figures/rcm-sorted.tex}
						
						\caption{RCM permutation}
						\label{fig:rcm-sorted}
					\end{subfigure}
					
					\caption{Adjacency matrix representation of a graph before and after
					permutation by the RCM algorithm.}
					\label{fig:rcm}
				\end{figure}
				
				A number of algorithms have been proposed for automatically selecting
				good vertex iteration orders, typically using a graph-traversal based
				heuristic. A typical method, described by Hoefler \emph{et al.}
				\cite{hoefler11} exploits the Reverse-Cuthill-McKee (RCM) algorithm
				\cite{cuthill69}. An application's communication matrix is represented
				as an adjacency matrix, $M$, where $M_{i,j}$ is 1 if node $i$ is
				connected by an edge to node $j$ and 0 otherwise. An example matrix is
				illustrated in figure \ref{fig:rcm-initial}. The RCM algorithm uses a
				simple heuristic to permute the matrix (i.e. renumber the nodes in the
				graph) in order to reduce the bandwidth of the matrix. Figure
				\ref{fig:rcm-sorted} shows the RCM-permuted version of the example
				adjacency matrix. When a graph's vertices are ordered as in a
				bandwidth-reduced sparse matrix, vertices close together in the
				ordering are likely to communicate while those further apart tend not
				to communicate.
				
			\subsubsection{Optimisation-based Placement}
				
				% Citations from short report about optimisation in placement...
				% \cite{chen06,jeannot14} and \cite{jeannot10} ("subsets of apps")
				
				In the academic community, a number of attempts have been made to use
				more sophisticated optimisation algorithms for the placement of
				applications. In 1985, Steele \cite{steele85} proposed the use of
				simulated annealing for placing applications in the 6D torus topology
				of the 64 node `Caltech Cosmic Cube' machine. Simulated annealing,
				originally developed by Kirkpatrick \emph{et al.} \cite{kirkpatrick83},
				is a general-purpose optimisation algorithm which works by analogy to
				the physical process of annealing. In brief simulated annealing
				functions by randomly swapping vertices in a candidate placement
				solution, accepting swaps which move connected vertices closer together
				and rejecting some proportion of swaps which move connected vertices
				further apart. The simulated annealing algorithm is described in detail
				later in this chapter.
				
				Towards the end of the 1980s, application placement appeared to be
				becoming less important as super computer network architectures
				improved:
				%
				\begin{displayquote}
					``Careful placement was necessary because of the slow communication
					and non-uniform addressing of early concurrent computers. However,
					the development of message passing machines with fast communications
					and a uniform global address space  has made placement less of an
					issue. In such machines a random placement performs nearly as well as
					an optimum placement.''
					
					\noindent --- W. Dally, 1987 \cite{dally87}
				\end{displayquote}
				%
				In addition, network and problem sizes remained small, so small in fact
				that linear-programming based optimal placement still appeared in
				benchmarks comparing placement algorithms \cite{xu91}. In this
				environment, simpler sequential placement algorithms gained favour over
				more computationally expensive algorithms such as simulated annealing.
				More recently `low temperature' simulated annealing has only been
				employed as a post-processing stage for other heuristic placers
				\cite{hoefler11} or reinvented only to be applied on 90s scale problems
				\cite{chen06}.
				
				As problem and machine sizes have grown and network utilisation has
				once again become an important factor in application performance
				\cite{navaridas09b} more complex optimisation algorithms have
				reappeared in the literature. One popular approach employs graph
				partitioning algorithms such as METIS \cite{karypis98} to perform
				recursive bipartitioning based placement
				\cite{phillips14,hoefler11,pellegrini96}.  This placement process is
				illustrated in figure \ref{fig:partitioning}.
				
				\begin{figure}
					\center
					\buildfig{figures/partitioning.tex}
					
					\caption{Illustration of application placement by recursive
					partitioning. Each node has the capacity to hold two vertices.}
					\label{fig:partitioning}
				\end{figure}
				
				In the first step, the application communication graph and machine
				connectivity graph are bipartitioned such that the number of edges
				between partitions is minimised. Each half of the communication graph
				is associated with one of the halves of the machine connectivity graph.
				The partitioning process is then repeated recursively on each of the
				two communication and connectivity graph pairs. The process halts when
				either of the graphs can no longer be partitioned. The vertices in the
				communication graph are then placed on their associated node in the
				connectivity graph.
				
				Unfortunately recursive partitioning-based techniques are known to
				perform sub-optimally when the number of nodes is not a power of two
				\cite{simon97}. In addition, placement problems are often subject to
				multiple orthogonal constraints, for example processor and memory
				requirements. Since the balance of a partition with multiple orthogonal
				resources depends on the eventual packing employed by a placement,
				partitioning-based algorithms may inadvertently become trapped by local
				minima.
				
				Other approaches employ other optimisation techniques but designed for
				use with networks particular connectivity patterns, for example trees
				\cite{jeannot14,traff02}. Since SpiNNaker's network structure does not
				match these architectures, these approaches are unsuitable.
	
		\subsection{Circuit placement algorithms}
			
			The circuit placement problem in chip and FPGA design is very similar to
			that of application placement, requiring communicating components to be
			assigned positions in some topology such that congestion is controlled.
			Modern CPUs have millions or billions of components and thus present a
			considerable placement problem often exceeding even the largest
			application problems. As such, chip placement algorithms may be well
			suited to tackling modern large-scale problems.
			
			A key difference between the circuit and application placement problems
			is that while super computer network topologies come in many shapes and
			forms, chips are generally strictly 2D and often constrained to Manhattan
			geometry (analagous to a 2D mesh topology) to simplify routing. As a
			result of this circuit placement algorithms often directly exploit
			geometric propoerties of the problem which may make them difficult to
			adapt to certain network topologies.
			
			Circuit placement techniques can be grouped into three broad categories
			\cite{kahng11}:
			
			\begin{description}
				
				\item[Partitioning-based] These algorithms function by recursively
				partitioning the circuit in order to group together related components.
				
				\item[Stochastic] These algorithms utilise stochastic search techniques
				such as simulated annelaing to generate placement solutions.
				
				\item[Analytical] These algorithms approximate the placement problem as
				another problem to which exact, or good, solutions can be found
				efficiently.
				
			\end{description}
			
			I assess the suitability of each of these techniques for use in
			application placement below. For a more detailed survey of circuit
			placement techniques the reader is referred to `VLSI physical design:
			from graph partitioning to timing closure' by Kahng \emph{et al.}
			\cite{kahng11}.
			
			\subsubsection{Partitioning-based placement}
				
				Partitioning based placement has a long history with early examples
				dating back to the 1970s \cite{breuer77}. As in partitioning-based
				application placement the input circuit is recursively partitioned
				alongside the target topology. Since the target topology is the 2D
				surface of a chip only simple geometric partitioning is required.
				
				Modern partitioning based placers such as Capo \cite{roy05} employ
				additional heuristics such as terminal propagation where connections
				between adjacent partitions are are considered to attempt to align
				components on either side of the cut.
				
				As in application placement, however, difficulties in generating good
				quality many-way partitions can negatively impact the performance of
				these algorithms. These approaches have since been largely superseded
				\cite{markov15}.
			
			\subsubsection{Stochastic techniques}
				
				The simulated annealing algorithm was originally developed specifically
				for the application of circuit placement \cite{kirkpatrick83} and
				rapidly gained popularity becoming the dominant circuit placement
				technique of the late 1980s and early 1990s when the first chips
				breaching the one-million component mark appeared
				\cite{betz97,sechen85}. Due to difficulties in scaling beyond
				tens-of-millions of components, plain simulated-annealing based
				techniques have dwindled in popularity. Despite this, simulated
				annealing remains popular in niche fields where flexibility is desired,
				such as the highly configurable Verilog-To-Routing (VTR) software suite
				\cite{luu14} and the Open Source Arachne-PNR \cite{cseed} placer.
				
				Various efforts continue to be made to speed up the simulated annealing
				process by attempting to partition the input problem into several
				independent problems \cite{choong10}, parallelise the search process
				\cite{ludwin08} and simply carrying out multiple searches starting from
				different random states \cite{haldar00}. As yet, substantial speed-ups
				have yet to emerge.
			
			\subsubsection{Analytical placement}
				
				The most recent generation of placement algorithms attempt to transform
				placement problems into approximately equivalent problems with
				closed-form solutions. One of the common trade-offs of these approaches
				is modelling components as point-like objects. As circuit designs have
				grown, this approximation has grown more accurate resulting in a boom
				in popularity \cite{markov15}.
				
				A popular analytical method employed by a number of circuit placement
				algorithms is `quadratic placement' \cite{kahng11,spindler08}. In this
				algorithm the components in a circuit are modelled as infinitesimal
				objects with connections between components modelled as spring-like
				forces. Unlike real springs which obey Hooke's law, the force exerted
				by a connection is proportional to the \emph{square} of its distance.
				
				\begin{figure}
					\center
					\buildfig{figures/quadratic-placement.tex}
					
					\caption{An optimal 1D quadratic placement solution for two fixed
					vertices ($f_1$ and $f_2$), two movable vertices ($m_1$ and $m_2$)
					and three weighted edges.}
					\label{fig:quadratic-placement}
				\end{figure}
				
				To illustrate this approach, consider the simple one-dimensional
				placement problem presented in figure \ref{fig:quadratic-placement}.
				In the quadratic placement technique, the cost of a placement is the
				weighted sum of the squares of the edge distances. In this case this
				yields:
				%
				\begin{equation*}
					\textrm{Cost} = 1(f_1 - m_1)^2 + 2(m_1 - m_2)^2 + 1(m_2 - f_2)^2
				\end{equation*}
				%
				An optimal placement is one which minimises this function. To find
				values which minimise a quadratic, the equation is differentiated
				yielding a system of linear equations. The linear equations are then
				solved to find the positions of the movable vertices which minimise the
				quadratic cost function.
				
				Quadratic placement is extended or 2 (or more dimensions) by simply
				applying the process for each dimension separately. Unfortunately, a
				straight-forward extension to non-euclidean geometries such as trees or
				even toruses is non trivial. For example, quadratic placement relies on
				cost increasing monotonically as two points are moved in opposite
				directions while in a torus this is not the case. Likewise in tree
				topologies, `movement' is not well defined.
				
				An additional challenge in quadratic placement is that some vertices'
				locations must be fixed in order to prevent a degenerate solution where
				all vertices have the same coordinate. In circuit placement, the
				locations of `pads' used to connect components in a circuit to the
				outside world are typically fixed and provide convenient anchors during
				placement. Algorithms such as SimPL \cite{kim12} employ a combination
				of analytical techniques in order to add virtual `anchor' components
				which prevent degenerate solutions from forming. Unfortunately this
				approach further adds to the difficulty of porting the technique to
				non-euclidean geometries.
				
				% TODO: mention viswanathan07 FastPlace 3.0 -- multilevel technique?
	
	\section{Application placement by simulated annealing}
		
		\label{sec:placement-by-annealing}	
		
		I have implemented a simplified SA based application placement algorithm
		based on the approach used in the popular VPR place and route tool chain.
		The algorithm is written in C and is optimised for experimentation rather
		than performance but is production-ready. It has been integrated into the
		`Rig' SpiNNaker software tools and has been used to place very large
		simulations. More on that later.
		
		\subsection{Representation}
			
			Model each chip as having a quantity of various resources (e.g. Cores,
			SDRAM) available. The application graph consists of vertices which each
			consume some quantity of these resources. Vertices must be placed on a
			single chip such that the resources required on a given chip do not
			exceed those available. Vertices are then interconnected by 1:N nets with
			weights which act as hints. The nets are treated as a soft constraint:
			vertices connected via a net will, ideally, be placed near to each other,
			with priority being given to nets with higher weights. Additionally there
			will be a list of placement constraints (see later).
			
			A key observation is that while vertices in an application may frequently
			have a 1:1 correspondence with application cores, this need-not be the
			case. For example, a vertex may represent a block of SDRAM which is
			shared. A vertex may also represent some other resource, for example,
			external IO availability. By making these resource types user-defined,
			applications programmers can express flexible hard-constraints on their
			application.
			
			Another observation is that generic soft constraints can be expressed may
			be expressed using a net with an appropriate weight.
			
			As a result of these facilities, application programmers can easily
			express their own application-specific hard and soft placement
			constraints without having to modify the algorithm. This representation
			has become a de-facto standard for placement problem interchange for
			SpiNNaker applications.
		
		\subsection{Cost function}
			
			At present I've used HPWL despite this being really bad for high-fan-out
			multicast and totally ignorant to the hexagonal nature of SpiNNaker...
			
			To compute bounding boxes for tori I use the following approach. For each
			dimension, sort the points on that dimension and find the largest gap
			between them on a ring. The bounding box goes the other way.
			
			TODO: FIGURE ILLUSTRATING BOUNDING BOX COMPUTATION FOR TORI.
		
		\subsection{Annealing schedule}
			
			The annealing schedule is that used by VPR. Despite being for circuit
			placement, it seems to work jolly well.
			
			TODO: DESCRIBE AND RATIONALISE THE SCHEDULE
		
		\subsection{Constraint handling}
			
			Various hard and soft constraints may be expressed by software
			approaches. For each we explain how they may be handled by the placement
			algorithm:
			
			\subsubsection{Location Constraint}
				
				The vertex is placed on a chip and removed from the set of movement
				candidates.
			
			\subsubsection{Same-chip constraint}
				
				When two vertices must always be placed on the same chip they are
				simply combined into one vertex which consumes the sum of their
				resources. Placement then treats them as one chip and thus is forced to
				atomically place the vertices.
			
			\subsubsection{Reserve resource constraint}
				
				Simply reduce resource availability on that chip.
			
			\subsubsection{Keep near Ethernet}
				
				Simply add a net.
	
	\section{Evaluation}
		
		\label{sec:placement-results}
		
		Though benchmarks exist for super computer loads and chip placement tasks,
		such things don't exist for neural applications. As a result I use a
		selection of real applications for SpiNNaker along with some synthetic
		benchmarks based on biological data.
		
		\subsection{Benchmark networks}
			
			First some real networks.
			
			Some nengo networks: SPAUN: `The world's largest functional brain model'.
			Word-net network from Jamie: Example of some learning.
			
			TODO: DESCRIBE SHAPE OF NENGO NETWORKS
			
			Some PyNN networks: Microcortical column model from PyNN. Note almost
			broadcast connectivity but varying weights. Try and extract a vision
			netlist from Anna. Maybe try and get a netlist for Tom's barrel cortex.
			
			Now for some artificial networks. Pipeline, noisy pipeline, mesh,
			Gaussian 2D.
		
		\subsection{Experiments}
			
			We compare random, linear, greedy and annealing based placement
			approaches to placement. We compare static metrics (such as mean/max
			congestion, table usage) along with experiments based on simulated
			network traffic in real hardware. Network Tester generates artificial
			traffic in proportion with the weights given for each model. We compare
			the relative level of traffic sustainable. We also consider use of
			machines of various sizes.
		
		\subsection{Results}
			
			SA placement is slow but rather effective, especially for some networks.
			Generally worth doing. Will need to be sped up for very large machines...
			
			TODO: EXPERIMENTS!
	
