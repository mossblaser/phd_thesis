\chapter{Conclusions and future research}
	
	The SpiNNaker architecture was designed to tackle the challenges presented by
	the simulation of biologically realistic neural networks. One of its
	distinguishing features is its network architecture which employs both an
	unconventional network topology and multicast router architecture. The
	hexagonal torus topology used by SpiNNaker was chosen to enable greater
	performance while maintaining ease of construction and scalability compared
	with conventional network topologies. SpiNNaker's router design centres
	around packets mimicking the neural `spike' signals they are designed to
	convey by being small, multicast and not guaranteed to arrive at their
	destination.  This novel design, though largely complete before this work
	began, left a number of open problems which this thesis has attempted to
	address.
	
	In this concluding chapter I begin by summarising the answers to the research
	questions raised in chapter~\ref{sec:introduction}. This is followed by a
	discussion of new research topics which have been uncovered by this work.
	
	\section{Answers to research questions}
		
		Each of the three research questions are answered below.
		
		\subsubsection{1. Can the hexagonal torus topology be deployed and used in
		real, large-scale systems?}
		
		In chapter~\ref{sec:building}, I introduced a cabling scheme and assembly
		technique which has been used successfully to build a prototype SpiNNaker
		system with over half a million processor cores using the hexagonal torus
		topology. The techniques shown are expected to enable a final SpiNNaker
		machine of double this size to be built, filling a six metre long row of
		machine-room cabinets.
		
		Though SpiNNaker's processor-count places it amongst some of the world's
		largest supercomputers (see figure \ref{fig:top500-num-processors} on page
		\pageref{fig:top500-num-processors}), it is comparatively compact, filling
		one row of cabinets compared with the warehouse-scale installations found
		in commercial systems. In spite of this, the folding and interleaving
		techniques described allow hexagonal torus topologies to scale to
		arbitrarily large installations without cables which span the machine.
		
		Chapter~\ref{sec:shortestPaths} described an efficient and general
		technique for finding, and enumerating shortest path vectors in hexagonal
		torus topologies. These developments bring the hexagonal torus topology in
		line with other topologies by enabling routing algorithms to exploit all
		possible paths in a network. Further, chapter~\ref{sec:placement}
		demonstrated that placement algorithms are also adaptable to hexagonal
		torus topologies thanks to their similarity to 2D toruses.
		
		Though, as this thesis highlights, hexagonal toruses lack many of the
		intuitive properties enjoyed by other topologies, it is still possible to
		reason about them with only limited computational effort.  Now that the
		practicality and scalability of the topology has also been demonstrated in
		practice, it represents a credible option for future network architectures.
		
		\subsubsection{2. Does SpiNNaker's router architecture help, or hinder
		fault tolerance?}
		
		SpiNNaker's unconventional use of packet dropping to avoid deadlocks
		greatly simplifies the router architecture, part of the motivation for this
		design. In chapter~\ref{sec:routing} this feature is used to the advantage
		of PGS repair to add fault tolerance to existing routing algorithms.
		Compared with the often complex and wasteful methods used to tolerate
		faults in other networks, PGS repair incurs very little performance
		overhead in the presence of static faults.
		
		Routing table usage does increase in the presence of faults, however, which
		may be a concern for applications which already require many routing table
		entries. Routing table usage, as well as other overheads, were most
		significantly increased in the presence of contiguous groups of network
		faults. This is because the PGS repair algorithm produces routes which pass
		tightly around the corners of faults, resulting in concentrations of
		routing table entries in those areas.  Though the symptoms of this problem
		can be attributed to the design of SpiNNaker's multicast routing mechanism,
		the responsibility lies with the behaviour of the PGS repair algorithm.
		Potential improvements to the PGS repair algorithm are discussed later in
		\S\ref{sec:pgs-repair-improvements}.
		
		The overall answer to this research question, therefore, is that the
		flexibility provided to routing algorithms in SpiNNaker's architecture is
		of great benefit, enabling arbitrary fault patterns to be inexpensively
		avoided.
		
		\subsubsection{3. How can the parts of a neural simulation be placed onto a
		large hexagonal torus topology to reduce network load?}
		
		In chapter~\ref{sec:placement}, I explored a number of contemporary
		approaches to the problem of placing applications with irregular
		communication patterns into network topologies. I observed that researchers
		working on circuit placement for chips and FPGAs are tackling similar
		problems and working at scales as large, or larger than, those faced in
		application placement. Based on this I developed a
		simulated annealing based placement algorithm inspired by the techniques
		used in circuit placement, with specific adaptations for use in application
		placement and SpiNNaker's network topology.
		
		The simulated annealing based placement algorithm consistently outperforms
		pre-existing placement algorithms included in benchmarks in terms of
		placement quality.  In the case of one benchmark, simulated annealing based
		placement made it possible to run that neural simulation in real-time for
		the first time.  At larger scales, simulated annealing was also found to be
		able to produce good quality placements in benchmarks containing over one
		million processes -- the largest size supported by the SpiNNaker
		architecture.
		
		The major shortcoming of simulated annealing based placement is its
		execution speed. Though its execution time grows in proportion to the size
		of the problem, the implementation used took over 12~hours to place a
		synthetic problem for the largest planned SpiNNaker machine. Though
		tractable -- particularly given the relative output quality compared with
		the prior state-of-the-art -- the algorithm is unlikely to function
		comfortably as-is on larger problems.
		
		The conclusion to be drawn from this result, however, is not just that
		simulated annealing is a good solution for today's placement problems but
		that circuit placement techniques in general could be successfully adapted
		to fulfil this role. The placement problems faced by chip designers are
		growing at roughly the same exponential rate as the size of super computers
		but circuit designs hold the lead in terms of problem size. Consequently,
		as approaches are retired by chip placement researchers, they may find new
		life in the field of application placement.
		
	\section{Future research}
		
		Though the goals of this study have largely been met, there also remain
		some important limitations which future work may hope to address.
		Furthermore, this work has uncovered a number of new research areas
		warranting future enquiry. This section outlines a number of future lines
		of research.
		
		\subsection{Warehouse-scale cabling}
			
			In chapter~\ref{sec:building} I developed and implemented a number of
			cabling schemes for the SpiNNaker architecture spanning up to a six metre
			row of machine-room cabinets -- a relatively small installation by
			current standards. In SpiNNaker, the cabling exists in a 2D plane (i.e.
			across the faces of the cabinets) but as the system is scaled up, a
			single row of cabinets will tend towards a 1D line. Since embedding a 2D
			structure in a 1D space necessarily results in long connections, this
			cannot scale indefinitely.
			
			\begin{figure}
				\center
				\buildfig{figures/multi-row-cabling.tex}
				
				\caption{Multiple rows of interconnected cabinets.}
				\label{fig:multi-row-cabling}
			\end{figure}
			
			In conventional large-scale super computer installations, nodes are
			installed in rows of cabinets as illustrated in
			figure~\ref{fig:multi-row-cabling}.  From a `bird's-eye' view, the system
			approximates a 2D space, spread across the floor of a machine-room.
			Therefore, in principle, the folding and interleaving techniques
			described in chapter~\ref{sec:building} still apply. Unfortunately for
			SpiNNaker, cables connecting between rows of cabinets would be longer
			than the one metre limit imposed by its hardware because of the spacing
			between rows of cabinets.  Future SpiNNaker systems will need to consider
			alternative link technologies.  For example, a hybrid system could be
			used in which intra-cabinet connections continue to use the current HSS
			link technology while inter-cabinet links might use optical connections.
			This type of architecture could be supported by the use of pluggable
			`SFP+' transceiver modules~\cite{sff01}.
		
		\subsection{Cabling assistance for other architectures}
			
			A secondary result of the construction of prototype SpiNNaker systems in
			chapter~\ref{sec:building} was the use of real-time guidance and feedback
			to assist cable installation. I am not aware of this technique's use by
			existing architectures and, following the success experienced in this
			project, it is possible that the technique may also be useful in
			conventional systems.
			
			During the construction of prototype SpiNNaker machines, each cable took
			seconds to install compared with the minutes reported for existing
			systems~\cite{mudigonda11}. Part of this increase in efficiency appears
			to result from the immediate identification of mistakes made during
			cabling, saving time-consuming backtracking later on.
			
			In many real-world network installations, units are less densely packed
			than in SpiNNaker and so longer cables are often required. As a
			consequence, cabling errors may become more likely as cabling patterns
			are spread over a larger area making them more difficult to visually
			verify. Like SpiNNaker, conventional networking hardware is often
			equipped with a generous range of indicator LEDs and diagnostic
			facilities which might be used to implement real-time installation
			guidance. Future work could explore the use of this technique in the
			construction of other large-scale networks, such as data centres.
		
		\subsection{Congestion mitigation}
			
			\label{sec:wiggly-board-allocations}
			
			In chapter~\ref{sec:routing} I found that contiguous network faults cause
			hot-spots of congestion and routing table depletion where the PGS repair
			algorithm routed many paths around the edges of faults.  However, it is
			not just faults which can cause contiguous blockages in the network
			topology. In reality, researchers do not always require a full-sized
			SpiNNaker system to perform their experiments so large SpiNNaker systems
			are soft-partitioned on demand into many smaller
			machines~\cite{spalloc16}. To ensure isolation between partitioned
			sub-machines, HSS links between boards in different partitions are
			disabled. Because of SpiNNaker's `wrapped triple' partitioning scheme,
			the resulting sub-machines have hexagonal \emph{mesh} topologies (i.e.
			without wrap-around links) with irregular boundaries as in
			figure~\ref{fig:spalloc-mesh}.
			
			\begin{figure}
				\center
				\buildfig{figures/spalloc-mesh.tex}
				
				\caption[Irregular edges of a partitioned SpiNNaker system.]%
				{Irregular edges in a SpiNNaker system comprised of 24~boards
				partitioned from a larger machine.  Each hexagon represents a SpiNNaker
				chip. No wrap-around connections are present.}
				\label{fig:spalloc-mesh}
			\end{figure}
			
			In partitioned systems, the `tooth'-like gaps on the periphery of the
			network result in similar congestion to the HSS link failures considered
			in chapter~\ref{sec:routing}. When a route is generated between nodes on
			opposite sides of a gap, the PGS repair process will produce a
			shortest-path route around it. Since many routes may be blocked by a
			single gap, a hot-spot may develop around the corners of the gap.
			
			In chapter~\ref{sec:placement}, the `CConv' benchmark application was
			found to run correctly the majority of the time when placed by the
			simulated annealing algorithm but would occasionally fail by a
			significant margin. Preliminary experiments suggest these occasional
			failures are caused by placement solutions which place heavily
			communicating parts of the application on opposite sides of gaps along
			the perimeter of the network. Two possible approaches which future work
			may consider are presented below.
			
			\subsubsection{Avoiding hotspots with PGS repair}
				
				\label{sec:pgs-repair-improvements}	
				
				Network congestion around faults and network irregularities could be
				reduced by forcing the PGS repair process to take more varied routes
				around faults. For example, in circuit routing algorithms, routers
				avoid congestion by increasing the cost of routes which pass through
				congested areas~\cite{kahng11}. A similar technique could be used in
				PGS repair to spread the routes it produces.
				
				An alternative approach would be to adapt the base routing algorithms
				used prior to PGS repair to, for example, attempt alternative dimension
				order routes which may avoid blockages due to faulty links.
			
			\subsubsection{Fault and irregularity aware placement}
				
				One of the shortcomings of the simulated annealing based placer
				developed in chapter~\ref{sec:placement} is that it does not account
				for network faults, or irregularities, when estimating the cost of
				placement solutions.  Future work may exploit techniques used in
				congestion-aware circuit placement which could be adapted for
				application placement~\cite{viswanathan07}.
		
		\subsection{Reducing placement execution time}
			
			The simulated annealing based placer presented in
			chapter~\ref{sec:placement} produced good quality placements but its
			execution time limits its use beyond one million vertex placement
			problems. Future work should explore possibilities for improving the
			performance and scalability of this technique.
			
			In addition to considering alternative placement algorithms based on
			other methods, one possible approach is to attempt to reduce the execution
			time of simulated annealing based placement by shrinking the application
			graph being placed.
			
			For example, graph clustering~\cite{schaeffer07} may be used to group
			together strongly connected vertices which would then be placed as a
			single unit.  Unfortunately, clustering can suffer from the same problems
			as graph-partitioning-based placement: vertices may be grouped together
			in ways which, in practice, cannot be packed together into a given portion
			of a machine.  A possible solution to this problem is to use a two-phase
			placement approach~\cite{kahng11}. In a `global' placement phase,
			solutions are permitted which can slightly over-allocate resources but
			overall achieve good placement quality. In the `detailed' placement phase
			which follows, the solution is `legalised' by making small changes to the
			global placement to eliminate over allocation.
			
			An alternative approach suited to SpiNNaker could be to limit the
			clustering process to clusters which fit on a single SpiNNaker chip. In
			typical SpiNNaker application graphs, clustering to this level may reduce
			placement problem sizes by an order of magnitude and, consequently,
			reduce execution times by the same ratio. Preliminary experiments suggest
			that this approach might result in little placement quality loss for
			large placement problems whilst substantially reducing overall execution
			time.
		
		\subsection{Benchmarking}
			
			One of the most significant limitations of this study has been the
			unavailability of large-scale SpiNNaker applications for use as
			benchmarks. As a consequence, much of the scalability experimentation
			performed has relied on simple synthetic benchmarks based on projections
			of future application behaviour.
			
			In the short term, more sophisticated synthetic benchmark generation
			techniques used by the circuit placement community~\cite{nam07} may offer
			alternative benchmarks for future work. In the longer term, however, it
			is hoped that the availability of large SpiNNaker systems -- and
			placement and routing algorithms better suited to exploit them -- will
			lead to larger scale applications being developed. Hopefully these
			applications will lead to more interesting and representative benchmarks
			for use in future work.
	
	\section{Closing remarks}
		
		One of the primary outcomes of this work is that a number of the practical
		challenges faced in scaling up the SpiNNaker architecture have been
		addressed leading to the construction of large-scale SpiNNaker machines.
		The development of an effective placement algorithm for SpiNNaker
		applications has been shown to enable some neural simulations to exploit
		SpiNNaker's architecture for the first time. The availability of larger
		SpiNNaker machines paves the way for future large-scale neural modelling
		work built on much larger models such as Spaun, `the world's largest
		functional brain model'~\cite{eliasmith12}.
		
		Beyond the SpiNNaker project, the hexagonal torus topology has also been
		validated as a scalable and practical candidate for future network
		architectures. As super computers become ever larger, the physical
		scalability afforded by the 2D nature of the hexagonal torus topology may
		make it a compelling option. In addition, the finding that circuit
		placement techniques can be adapted to support placement of SpiNNaker
		software indicates that these algorithms may also be applicable to other
		applications. Indeed, if this is the case, circuit placement may offer a
		long-term source of placement algorithms able to handle the demands of
		future applications.
		
		% This thesis has explored and tackled a number of the challenges posed in
		% scaling up the unconventional SpiNNaker architecture. Along the way I have
		% demonstrated that the hexagonal torus topology may be a practical choice in
		% future applications which can scale up to the physical dimensions expected
		% of future super computers. I have also developed new efficient and
		% effective methods of placing and routing neural simulation software on
		% SpiNNaker which -- it is hoped -- will enable a new generation of large
		% scale neural simulations on spinnaker.
		
		Although this work stops short of demonstrating truly large-scale
		neuroscientific simulations running at the scale of newly completed
		SpiNNaker machines (largely because such simulations do not yet exist) a
		number of smaller-scale neural simulations have been made possible for the
		first time. The algorithms and techniques devised in this work have
		subsequently been incorporated into various software libraries and tools
		now being used by researchers building SpiNNaker applications, vindicating
		the efforts of this thesis (see appendix~\ref{sec:software}). A successor
		to the SpiNNaker architecture is also in the early stages of design and is
		building on experience of the existing architecture. The current intention
		is to retain the hexagonal torus topology used by SpiNNaker, a decision
		supported by the findings of this thesis.
		
		With SpiNNaker's hardware architecture now operating at scales close to its
		architectural limits, it is hoped that the contributions of this work will
		enable researchers to develop larger and more detailed neural models for
		this unique architecture.
